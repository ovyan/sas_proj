{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:20:01.687040Z",
     "start_time": "2021-06-15T20:19:54.210624Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from catboost.utils import eval_metric\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:20:02.204754Z",
     "start_time": "2021-06-15T20:20:01.738713Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_lt.csv\")\n",
    "df.drop('PRODUCT_RK', axis=1, inplace=True)\n",
    "df.drop('PRODUCT_RK_y', axis=1, inplace=True)\n",
    "df.drop('STORE_LOCATION_RK', axis=1, inplace=True)\n",
    "df['is_train'] = ~df.demand.isna() # mark non-nan demand as train observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:20:02.261232Z",
     "start_time": "2021-06-15T20:20:02.257575Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: think about filling NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:22:42.140990Z",
     "start_time": "2021-06-15T20:20:02.295956Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2137/2137 [02:39<00:00, 13.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# for each product this fills NaNs with the mean specific for this product and store\n",
    "for product in tqdm(df['product_rk'].unique()):\n",
    "    t = df[df['product_rk'] == product]\n",
    "    for store in t['store_location_rk'].unique():\n",
    "        g = t[t['store_location_rk'] == store]\n",
    "        g['PRICE_REGULAR'] = g['PRICE_REGULAR'].fillna(g[\"PRICE_REGULAR\"].mean())\n",
    "        g['PRICE_AFTER_DISC'] = g['PRICE_AFTER_DISC'].fillna(g[\"PRICE_AFTER_DISC\"].mean())\n",
    "        t[t['store_location_rk'] == store] = g\n",
    "    \n",
    "    df[df['product_rk'] == product] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:23:21.054907Z",
     "start_time": "2021-06-15T20:22:42.218722Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2137/2137 [00:38<00:00, 55.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# for those rows that are still empty we fillna by mean demand for the product (without store)\n",
    "for product in tqdm(df['product_rk'].unique()):\n",
    "    t = df[df['product_rk'] == product]\n",
    "    t['PRICE_REGULAR'] = t['PRICE_REGULAR'].fillna(g[\"PRICE_REGULAR\"].mean())\n",
    "    t['PRICE_AFTER_DISC'] = t['PRICE_AFTER_DISC'].fillna(g[\"PRICE_AFTER_DISC\"].mean())\n",
    "    df[df['product_rk'] == product] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:23:43.204761Z",
     "start_time": "2021-06-15T20:23:43.190687Z"
    }
   },
   "outputs": [],
   "source": [
    "df['demand'] = df['demand'].fillna(-1).astype(int) # fill nan demand as -1 to avoid crashing\n",
    "df['DISCOUNT'] = df['PRICE_AFTER_DISC'] / df['PRICE_REGULAR']\n",
    "df['is_discount'] = df['DISCOUNT'] != 1 \n",
    "\n",
    "# TODO: натренить на обычно лаге в текущем году. когда предсказываем -> идем последовательно от января до декабря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:23:49.892848Z",
     "start_time": "2021-06-15T20:23:48.223522Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data_fixed.csv\", index=False) # checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:24:46.069400Z",
     "start_time": "2021-06-15T20:24:45.970952Z"
    }
   },
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['week_number'] = df['date'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:26:55.847194Z",
     "start_time": "2021-06-15T20:26:55.786310Z"
    }
   },
   "outputs": [],
   "source": [
    "df['years'] = df['date'].dt.year\n",
    "df['months'] = df['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:53:54.221796Z",
     "start_time": "2021-06-15T20:53:54.202662Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_newyear(df):\n",
    "    df['NewYear'] = 0\n",
    "    t = df[(df['years'].isin([2016, 2017, 2018, 2019]))&(df['week_number'].isin([51, 52]))]\n",
    "    t['NewYear'] = 1\n",
    "    df[(df['years'].isin([2016, 2017, 2018, 2019]))&(df['week_number'].isin([51, 52]))] = t\n",
    "    return df\n",
    "\n",
    "def add_feb14(df):\n",
    "    df['is_feb14'] = 0\n",
    "    t = df[(df['years'].isin([2016]))&(df['week_number'].isin([6]))]\n",
    "    t['is_feb14'] = 1\n",
    "    df[(df['years'].isin([2016]))&(df['week_number'].isin([6]))] = t\n",
    "    \n",
    "    t = df[(df['years'].isin([2017, 2018]))&(df['week_number'].isin([6, 7]))]\n",
    "    t['is_feb14'] = 1\n",
    "    df[(df['years'].isin([2017, 2018]))&(df['week_number'].isin([6, 7]))] = t\n",
    "    \n",
    "    t = df[(df['years'].isin([2019]))&(df['week_number'].isin([7]))]\n",
    "    t['is_feb14'] = 1\n",
    "    df[(df['years'].isin([2019]))&(df['week_number'].isin([7]))] = t\n",
    "    return df\n",
    "\n",
    "def add_march8(df):\n",
    "    df['is_march8'] = 0\n",
    "    t = df[(df['years'].isin([2016, 2017, 2018, 2019]))&(df['week_number'].isin([9, 10]))]\n",
    "    t['is_march8'] = 1\n",
    "    df[(df['years'].isin([2016, 2017, 2018, 2019]))&(df['week_number'].isin([9, 10]))] = t\n",
    "    return df\n",
    "\n",
    "def add_september1(df):\n",
    "    df['is_september1'] = 0\n",
    "    t = df[(df['years'].isin([2016, 2017, 2018, 2019]))&(df['week_number'].isin([35]))]\n",
    "    t['is_september1'] = 1\n",
    "    df[(df['years'].isin([2016, 2017, 2018, 2019]))&(df['week_number'].isin([35]))] = t\n",
    "    return df\n",
    "\n",
    "def add_blackFR(df):\n",
    "    df['is_blackFR'] = 0\n",
    "    t = df[(df['years'].isin([2016, 2017, 2018]))&(df['week_number'].isin([47]))]\n",
    "    t['is_blackFR'] = 1\n",
    "    df[(df['years'].isin([2016, 2017, 2018]))&(df['week_number'].isin([47]))] = t\n",
    "    \n",
    "    t = df[(df['years'].isin([2019]))&(df['week_number'].isin([48]))]\n",
    "    t['is_blackFR'] = 1\n",
    "    df[(df['years'].isin([2019]))&(df['week_number'].isin([48]))] = t\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:54:24.792577Z",
     "start_time": "2021-06-15T20:54:24.255075Z"
    }
   },
   "outputs": [],
   "source": [
    "df = add_newyear(df)\n",
    "df = add_feb14(df)\n",
    "df = add_march8(df)\n",
    "df = add_september1(df)\n",
    "df = add_blackFR(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:55:23.665514Z",
     "start_time": "2021-06-15T20:55:19.904358Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data_holidays.csv\", index=False) # checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:22:57.785499Z",
     "start_time": "2021-06-15T21:22:57.305099Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_holidays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:22:58.762721Z",
     "start_time": "2021-06-15T21:22:58.753371Z"
    }
   },
   "outputs": [],
   "source": [
    "is_test = [0]*len(df) # creating is_test columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:22:59.487374Z",
     "start_time": "2021-06-15T21:22:59.461968Z"
    }
   },
   "outputs": [],
   "source": [
    "smp = pd.read_csv(\"sample_lt.csv\") # reading sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:23:00.116286Z",
     "start_time": "2021-06-15T21:23:00.108530Z"
    }
   },
   "outputs": [],
   "source": [
    "for idd in smp['index']: # mark those rows that appear in the test as is_test=1\n",
    "    is_test[idd] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:23:00.757687Z",
     "start_time": "2021-06-15T21:23:00.702232Z"
    }
   },
   "outputs": [],
   "source": [
    "df['is_test'] = is_test # save this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:23:01.479217Z",
     "start_time": "2021-06-15T21:23:01.397507Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove rows which are not in the test or train. (Maybe there are rows with NaN demand that are not in the test)\n",
    "df = df[(df['is_test']==1)|(df['is_train']==1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:23:02.126610Z",
     "start_time": "2021-06-15T21:23:02.101465Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop('date', axis=1) # remove unnecessary date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: skip next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:56:57.214930Z",
     "start_time": "2021-06-15T20:56:57.177016Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove products that are not presented in the test \n",
    "# (this didn't decreased or increased score on Kaggle, maybe shouldn't remove in the future)\n",
    "test_prods = df[df['is_test']==1].product_rk.unique() \n",
    "df = df[df['product_rk'].isin(test_prods)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:23:05.041387Z",
     "start_time": "2021-06-15T21:23:05.035284Z"
    }
   },
   "outputs": [],
   "source": [
    "df['weeklag1'] = 0\n",
    "df['weeklag2'] = 0\n",
    "df['yearlag1'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:32:59.875936Z",
     "start_time": "2021-06-15T21:23:08.344385Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2137/2137 [09:51<00:00,  3.61it/s]\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "ii = 0\n",
    "for product in tqdm(df['product_rk'].unique()): # run over unique products\n",
    "    ii += 1\n",
    "    temp_arr = []\n",
    "    prod_df = df[df['product_rk'] == product]\n",
    "    # TODO: calculate lags for stores\n",
    "    for index, row in prod_df.iterrows():\n",
    "        product_rk = row['product_rk']\n",
    "        weeknum = row['week_number']\n",
    "        year = row['years']\n",
    "        year = int(year)\n",
    "\n",
    "        # weeklag from prev year\n",
    "        for i in [1, 2]: # 1, 2 since we only have weeklag1, weeklag2\n",
    "            new_weeknum = weeknum - i\n",
    "            new_year = year - 1\n",
    "            if new_weeknum < 0: # if it was first week of the year we might get week 0 or -1\n",
    "                new_weeknum = new_weeknum % 52 + 1\n",
    "                new_year = year - 1\n",
    "            # looking for lags a year ago\n",
    "            lag = prod_df[(prod_df['years']==(new_year))&(prod_df['week_number']==(new_weeknum))] \n",
    "            if len(lag) >= 1: # lags found\n",
    "                lag = lag['demand'].mean() # TODO: median\n",
    "            elif len(lag) == 0: # no lags\n",
    "                lag = 0\n",
    "            elif lag['demand'].values[0] == -1: # if demand is NaN\n",
    "                lag = 0\n",
    "            row[f'weeklag{i}'] = lag\n",
    "\n",
    "        #yearlag\n",
    "        for i in [1]:\n",
    "            lag = prod_df[(prod_df['years']==(year-1))&(prod_df['week_number']==(weeknum))]\n",
    "            if len(lag) >= 1:\n",
    "                lag = lag['demand'].mean() # TODO: median\n",
    "            elif len(lag) == 0:\n",
    "                lag = 0\n",
    "            elif lag['demand'].values[0] == -1:\n",
    "                lag = 0\n",
    "            row[f'yearlag{i}'] = lag\n",
    "        temp_arr.append(row)\n",
    "        \n",
    "    tt = pd.DataFrame.from_dict(temp_arr)\n",
    "    final_df = final_df.append(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:17:12.945482Z",
     "start_time": "2021-06-15T21:17:12.934589Z"
    }
   },
   "outputs": [],
   "source": [
    "df = final_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:17:15.491125Z",
     "start_time": "2021-06-15T21:17:14.011146Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('data+lags.csv', index=False) # checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:17:16.505669Z",
     "start_time": "2021-06-15T21:17:16.498236Z"
    }
   },
   "outputs": [],
   "source": [
    "df['SKU'] = df['product_rk'] * 100000 + df['store_location_rk'] # creating SKU column for unique pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:17:17.248256Z",
     "start_time": "2021-06-15T21:17:17.192510Z"
    }
   },
   "outputs": [],
   "source": [
    "uniq_skus = df[df['is_test']==0]['SKU'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:17:17.815218Z",
     "start_time": "2021-06-15T21:17:17.810774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11550"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniq_skus) # number of unique pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:17:18.336950Z",
     "start_time": "2021-06-15T21:17:18.334227Z"
    }
   },
   "outputs": [],
   "source": [
    "val_skus = uniq_skus[::4] # take 1/4 or 25% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:17:18.868251Z",
     "start_time": "2021-06-15T21:17:18.863097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2888"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_skus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:17:20.052960Z",
     "start_time": "2021-06-15T21:17:19.965807Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df[(df['is_train']==1)].drop(['id', 'demand', 'is_train', \n",
    "                                  'is_test', 'SKU', 'years'], axis=1)\n",
    "y = df[df['is_train']==1]['demand']\n",
    "\n",
    "# it is train, SKU not in validation and year is < 2018\n",
    "X_train = df[(df['is_train']==1)&(~df['SKU'].isin(val_skus))&(df['years']<2018)].drop(['id', 'demand', \n",
    "                                                                                        'is_train', 'is_test', \n",
    "                                                                                        'SKU', 'years'], \n",
    "                                                                                        axis=1)\n",
    "y_train = df[(df['is_train']==1)&(~df['SKU'].isin(val_skus))&(df['years']<2018)]['demand']\n",
    "\n",
    "# it is train, SKU in validation and year is 2018\n",
    "X_test = df[(df['is_train']==1)&(df['SKU'].isin(val_skus))&(df['years']==2018)].drop(['id', 'demand', \n",
    "                                                                                       'is_train', 'is_test', \n",
    "                                                                                       'SKU', 'years'], \n",
    "                                                                                       axis=1)\n",
    "y_test = df[(df['is_train']==1)&(df['SKU'].isin(val_skus))&(df['years']==2018)]['demand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:17:22.836632Z",
     "start_time": "2021-06-15T21:17:22.828456Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_features = ['product_rk', 'PROMO1_FLAG', 'is_blackFR', 'is_feb14', 'store_location_rk',\n",
    "                'is_march8', 'NewYear', 'is_september1', 'PROMO2_FLAG', 'AUTORIZATION_FLAG', 'is_discount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T08:21:33.699076Z",
     "start_time": "2021-05-20T08:21:33.694074Z"
    }
   },
   "outputs": [],
   "source": [
    "# my own grid search\n",
    "for ls in ['MAE']:\n",
    "    for leaf in [7, 9]: # 7, 9, 11\n",
    "        for iterations in [1000]:\n",
    "            for depth in [4, 6, 8]:\n",
    "                lr = 0.1\n",
    "                cat = CatBoostRegressor(loss_function=ls, # TODO: try another losses\n",
    "                                        eval_metric='SMAPE',\n",
    "                                        learning_rate=lr,\n",
    "                                        metric_period=100,\n",
    "                                        l2_leaf_reg=leaf,\n",
    "                                        depth=depth,\n",
    "                                        iterations=iterations, random_state=0)\n",
    "\n",
    "                cat.fit(X_train, y_train, cat_features, verbose=False)\n",
    "                preds = cat.predict(X_test)\n",
    "                preds = preds.clip(min=0)\n",
    "                res = eval_metric(y_test.values, preds, 'SMAPE')\n",
    "                print('leaf:', leaf, ', lr:', lr, ', depth:', depth, ', iterations:', iterations, ls, ', res:', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:21:21.549420Z",
     "start_time": "2021-06-15T21:21:14.236309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 196.6543601\ttotal: 25.2ms\tremaining: 12.6s\n",
      "100:\tlearn: 171.4214431\ttotal: 1.38s\tremaining: 5.43s\n",
      "200:\tlearn: 169.5746620\ttotal: 2.61s\tremaining: 3.89s\n",
      "300:\tlearn: 169.0284715\ttotal: 4.14s\tremaining: 2.73s\n",
      "400:\tlearn: 168.4988283\ttotal: 5.74s\tremaining: 1.42s\n",
      "499:\tlearn: 168.3547374\ttotal: 6.94s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7fcc91a9e160>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base model\n",
    "cat = CatBoostRegressor(loss_function='MAE', # TODO: try another losses\n",
    "                        eval_metric='SMAPE',\n",
    "                        learning_rate=0.1,\n",
    "                        metric_period=100,\n",
    "                        iterations=500,\n",
    "                        l2_leaf_reg=4,\n",
    "                        depth=5,\n",
    "                        random_state=0)\n",
    "\n",
    "cat.fit(X_train, y_train, cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:21:22.216443Z",
     "start_time": "2021-06-15T21:21:22.101207Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = cat.predict(X_test)\n",
    "preds = preds.clip(min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:21:22.815964Z",
     "start_time": "2021-06-15T21:21:22.808791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[146.79064233851966]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metric(y_test.values, preds, 'SMAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:21:23.378132Z",
     "start_time": "2021-06-15T21:21:23.364746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55.87276156335722]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try this one :D\n",
    "eval_metric(y_test.values, preds.astype(int), 'SMAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:21:25.334661Z",
     "start_time": "2021-06-15T21:21:25.326200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.02590742053221 product_rk\n",
      "15.306320013202267 store_location_rk\n",
      "7.284049009536575 PROMO1_FLAG\n",
      "0.053359530577006035 PROMO2_FLAG\n",
      "0.3698406680333062 PRICE_REGULAR\n",
      "0.23419497106647302 PRICE_AFTER_DISC\n",
      "0.1994755222935547 NUM_CONSULTANT\n",
      "2.8160063510257864 AUTORIZATION_FLAG\n",
      "21.596744750718074 DISCOUNT\n",
      "0.1874866205015876 is_discount\n",
      "9.735960937379746 week_number\n",
      "6.281238082766466 months\n",
      "4.606499327287438 NewYear\n",
      "7.21108522715423e-05 is_feb14\n",
      "0.01094268439785081 is_march8\n",
      "0.004835416805536783 is_september1\n",
      "0.008402272061585902 is_blackFR\n",
      "0.0 weeklag1\n",
      "0.15051921760101547 weeklag2\n",
      "0.12814509336126284 yearlag1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cat.feature_importances_)):\n",
    "    print(cat.feature_importances_[i], cat.feature_names_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:21:45.999935Z",
     "start_time": "2021-06-15T21:21:26.978899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 195.1393077\ttotal: 68.3ms\tremaining: 34.1s\n",
      "100:\tlearn: 171.6940928\ttotal: 4.44s\tremaining: 17.5s\n",
      "200:\tlearn: 166.2999069\ttotal: 8.03s\tremaining: 11.9s\n",
      "300:\tlearn: 165.5156632\ttotal: 11.3s\tremaining: 7.44s\n",
      "400:\tlearn: 164.5603469\ttotal: 14.8s\tremaining: 3.65s\n",
      "499:\tlearn: 164.0361941\ttotal: 18.2s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7fcc91a9e160>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.fit(X, y, cat_features) # more iterations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:21:46.574207Z",
     "start_time": "2021-06-15T21:21:46.563536Z"
    }
   },
   "outputs": [],
   "source": [
    "X_res = df[df['is_test']==1].drop(['id', 'demand', 'is_train', 'is_test', 'SKU',\n",
    "                                          'years'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:21:47.302763Z",
     "start_time": "2021-06-15T21:21:47.128967Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = cat.predict(X_res)\n",
    "preds = preds.clip(min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:21:47.849763Z",
     "start_time": "2021-06-15T21:21:47.832321Z"
    }
   },
   "outputs": [],
   "source": [
    "smp = pd.read_csv(\"sample_lt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:22:01.707999Z",
     "start_time": "2021-06-15T21:21:48.365512Z"
    }
   },
   "outputs": [],
   "source": [
    "ans = []\n",
    "# check test observation we already had not NaN demand\n",
    "given_answers = df[(df['is_train']==1)&(df['is_test']==1)] \n",
    "\n",
    "for index, idd in enumerate(smp['index'].values):\n",
    "    if len(given_answers[given_answers['id']==idd].demand.values) != 0: # if for this id demand already exists\n",
    "        ans.append(given_answers[given_answers['id']==idd].demand.values[0]) # then overwrite the prediction\n",
    "    else:\n",
    "        ans.append(preds[index]) # otherwise save prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:22:02.292299Z",
     "start_time": "2021-06-15T21:22:02.283888Z"
    }
   },
   "outputs": [],
   "source": [
    "smp['demand'] = ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:22:03.005336Z",
     "start_time": "2021-06-15T21:22:02.895396Z"
    }
   },
   "outputs": [],
   "source": [
    "smp.to_csv(\"like+mike+lag+l2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
